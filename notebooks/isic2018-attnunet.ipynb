{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport os\nimport glob\nimport cv2\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport random\nfrom mpl_toolkits.axes_grid1 import ImageGrid\nfrom sklearn.model_selection import train_test_split\nimport copy\nfrom tqdm import tqdm\n\nimport torch\nfrom torch import nn, cat, squeeze\nimport torchvision\nfrom torchvision import transforms as T\nfrom torchvision.transforms import functional as F\nfrom PIL import Image\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-03-08T10:06:33.843574Z","iopub.execute_input":"2022-03-08T10:06:33.844258Z","iopub.status.idle":"2022-03-08T10:06:36.986952Z","shell.execute_reply.started":"2022-03-08T10:06:33.844159Z","shell.execute_reply":"2022-03-08T10:06:36.986183Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"TRAIN_IMG_PATH = '../input/isic2018/ISIC2018_Task1-2_Training_Input/ISIC2018_Task1-2_Training_Input'\nTRAIN_MASK_PATH = '../input/isic2018/ISIC2018_Task1_Training_GroundTruth/ISIC2018_Task1_Training_GroundTruth'\nVAL_IMG_PATH = '../input/isic2018/ISIC2018_Task1-2_Validation_Input/ISIC2018_Task1-2_Validation_Input'\nVAL_MASK_PATH = '../input/isic2018/ISIC2018_Task1_Validation_GroundTruth/ISIC2018_Task1_Validation_GroundTruth'\n\n# train_img = os.listdir(TRAIN_IMG_PATH)\ntrain_img = glob.glob(TRAIN_IMG_PATH + '*/*.jpg')\ntrain_mask = glob.glob(TRAIN_MASK_PATH + '*/*.png')\n\nval_img = glob.glob(VAL_IMG_PATH + '*/*.jpg')\nval_mask = glob.glob(VAL_MASK_PATH + '*/*.png')","metadata":{"execution":{"iopub.status.busy":"2022-03-08T10:06:36.989315Z","iopub.execute_input":"2022-03-08T10:06:36.989847Z","iopub.status.idle":"2022-03-08T10:06:37.635061Z","shell.execute_reply.started":"2022-03-08T10:06:36.989809Z","shell.execute_reply":"2022-03-08T10:06:37.634332Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f'Len train image:', len(train_img))\nprint(f'Len train mask:', len(train_mask))\nprint(f'Len val image:', len(val_img))\nprint(f'Len val mask:', len(val_mask))","metadata":{"execution":{"iopub.status.busy":"2022-03-08T10:06:37.636557Z","iopub.execute_input":"2022-03-08T10:06:37.636817Z","iopub.status.idle":"2022-03-08T10:06:37.644058Z","shell.execute_reply.started":"2022-03-08T10:06:37.636781Z","shell.execute_reply":"2022-03-08T10:06:37.643010Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.DataFrame({'image_path':sorted(train_img), 'mask_path':sorted(train_mask), 'split':'train'})\ndf2 = pd.DataFrame({'image_path':sorted(val_img), 'mask_path':sorted(val_mask), 'split':'val'})\ndf = df.append(df2)\ndf","metadata":{"execution":{"iopub.status.busy":"2022-03-08T10:06:37.646838Z","iopub.execute_input":"2022-03-08T10:06:37.647189Z","iopub.status.idle":"2022-03-08T10:06:37.676646Z","shell.execute_reply.started":"2022-03-08T10:06:37.647151Z","shell.execute_reply":"2022-03-08T10:06:37.676003Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\"\"\"\nThe dataset was split into three subsets, training set, validation set, and test set, which the proportion is 70%, 10% and 20% of the whole dataset, respectively\n\"\"\"\nseed = 108\ndf = df.reset_index(drop=True)\ndf_train = df[df['split']=='train']\ntrain_df, df_ = train_test_split(df_train, shuffle=True, train_size=0.8, random_state=seed)\nval_df, test_df = train_test_split(df_, shuffle=True, train_size=0.5, random_state=seed)\ntest_df = test_df.append(df[df['split']=='val'])\nprint('Train - Valid - Test set size')\nprint(f'Train: {train_df.shape}\\nValid: {val_df.shape}\\nTest: {test_df.shape}')","metadata":{"execution":{"iopub.status.busy":"2022-03-08T10:06:37.677815Z","iopub.execute_input":"2022-03-08T10:06:37.678056Z","iopub.status.idle":"2022-03-08T10:06:37.695967Z","shell.execute_reply.started":"2022-03-08T10:06:37.678024Z","shell.execute_reply":"2022-03-08T10:06:37.695130Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"IMG_SIZE = 224\nimages = []\nmasks = []\nfor data in train_df.sample(5).values:\n    img = cv2.resize(cv2.imread(data[0]), (IMG_SIZE, IMG_SIZE))\n    mask = cv2.resize(cv2.imread(data[1]), (IMG_SIZE, IMG_SIZE))\n    images.append(img)\n    masks.append(mask)\nimages = np.hstack(np.array(images))\nmasks = np.hstack(np.array(masks))\n\nfig = plt.figure(figsize=(25,25))\ngrid = ImageGrid(fig, 111, nrows_ncols=(3,1), axes_pad=0.5)\n\ngrid[0].imshow(images)\ngrid[0].set_title('Images', fontsize=20)\ngrid[0].axis('off')\ngrid[1].imshow(masks)\ngrid[1].set_title('Masks', fontsize=20)\ngrid[1].axis('off')\ngrid[2].imshow(images)\ngrid[2].imshow(masks, alpha=0.4)\ngrid[2].set_title('Image with mask', fontsize=20)\ngrid[2].axis('off')","metadata":{"execution":{"iopub.status.busy":"2022-03-08T10:06:37.697131Z","iopub.execute_input":"2022-03-08T10:06:37.697350Z","iopub.status.idle":"2022-03-08T10:06:40.721568Z","shell.execute_reply.started":"2022-03-08T10:06:37.697320Z","shell.execute_reply":"2022-03-08T10:06:40.719968Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def show_img(inputs, nrows=4, ncols=4, image=True):\n    plt.figure(figsize=(10, 10))\n    plt.subplots_adjust(wspace=0., hspace=0.)\n    if len(inputs) > nrows*ncols:\n        inputs = inputs[:nrows*ncols]\n    \n    for i in range(len(inputs)):\n        if image is True:\n            img = inputs[i].numpy().transpose(1,2,0)\n            mean = [0.5, 0.5, 0.5]\n            std = [0.5, 0.5, 0.5]\n            img = (img*std + mean).astype(np.float32)\n        else:\n            img = inputs[i].numpy().astype(np.float32)\n            img = img[0,:,:]\n        plt.subplot(nrows, ncols, i+1)\n        plt.imshow(img)\n        plt.axis('off')\n    return plt.show()","metadata":{"execution":{"iopub.status.busy":"2022-03-08T10:06:40.722705Z","iopub.execute_input":"2022-03-08T10:06:40.722983Z","iopub.status.idle":"2022-03-08T10:06:40.732803Z","shell.execute_reply.started":"2022-03-08T10:06:40.722933Z","shell.execute_reply":"2022-03-08T10:06:40.732040Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img = cv2.imread(data[0])\nmask = cv2.imread(data[1])\nprint(img.shape)\nprint(mask.shape)","metadata":{"execution":{"iopub.status.busy":"2022-03-08T10:06:40.734427Z","iopub.execute_input":"2022-03-08T10:06:40.734932Z","iopub.status.idle":"2022-03-08T10:06:40.900682Z","shell.execute_reply.started":"2022-03-08T10:06:40.734898Z","shell.execute_reply":"2022-03-08T10:06:40.899831Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"IMG_SIZE = 224\nclass SkinLesionDataset(torch.utils.data.Dataset):\n    def __init__(self, df, image_size=IMG_SIZE, mode='train', augmentation_prob=0.4):\n        self.df = df\n        self.image_size = IMG_SIZE\n        self.mode = mode\n        self.augmentation_prob = augmentation_prob\n        self.RotationDegree = [0, 90, 180, 270]\n        \n    def __len__(self):\n        return len(self.df)\n    \n    def __getitem__(self, idx):\n        image = Image.open(self.df.iloc[idx, 0])\n        mask = Image.open(self.df.iloc[idx, 1])\n        \n        aspect_ratio = image.size[1]/image.size[0]\n        \n        Transform = []\n        p_transform = random.random()\n        Transform.append(T.Resize((self.image_size, self.image_size)))\n        if (self.mode=='train') and p_transform <= self.augmentation_prob:\n            RotationDegree = self.RotationDegree[random.randint(0, 3)]\n            if (RotationDegree == 90) or (RotationDegree == 270):\n                aspect_ratio = 1/aspect_ratio\n            Transform.append(T.RandomRotation(RotationDegree))\n            \n            Transform.append(T.RandomRotation(10))\n            CropRange = random.randint(250,270)\n            Transform.append(T.CenterCrop((int(CropRange*aspect_ratio),CropRange)))\n            Transform = T.Compose(Transform)\n            \n            image = Transform(image)\n            mask = Transform(mask)\n            \n            if random.random() < 0.5:\n                image = F.hflip(image)\n                mask = F.hflip(mask)\n            if random.random() < 0.5:\n                image = F.vflip(image)\n                mask = F.vflip(mask)\n            \n            Transform = []                \n            image = T.ColorJitter(brightness=0.2,contrast=0.2,hue=0.02)(image)\n            \n        Transform.append(T.Resize((self.image_size, self.image_size)))\n        Transform.append(T.ToTensor())\n        Transform = T.Compose(Transform)\n        \n        image = Transform(image)\n        mask = Transform(mask)\n        \n        image = T.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))(image)\n        return image, mask","metadata":{"execution":{"iopub.status.busy":"2022-03-08T10:06:40.901907Z","iopub.execute_input":"2022-03-08T10:06:40.902200Z","iopub.status.idle":"2022-03-08T10:06:40.917495Z","shell.execute_reply.started":"2022-03-08T10:06:40.902159Z","shell.execute_reply":"2022-03-08T10:06:40.916558Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataframe = {'train':train_df, 'val':val_df, 'test':test_df}\ndataset = {x:SkinLesionDataset(dataframe[x], mode=x) for x in ['train', 'val', 'test']}\ndataloader = {x:torch.utils.data.DataLoader(dataset[x], batch_size=16, shuffle=True, num_workers=2) for x in ['train', 'val', 'test']}\nsizes = {x:len(dataloader[x]) for x in ['train','val','test']}\nsizes","metadata":{"execution":{"iopub.status.busy":"2022-03-08T10:06:40.921061Z","iopub.execute_input":"2022-03-08T10:06:40.921815Z","iopub.status.idle":"2022-03-08T10:06:40.935716Z","shell.execute_reply.started":"2022-03-08T10:06:40.921772Z","shell.execute_reply":"2022-03-08T10:06:40.934953Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"images, masks = next(iter(dataloader['train']))\nprint(images.shape)\nprint(masks.shape)\nshow_img(images)\nshow_img(masks, image=False)","metadata":{"execution":{"iopub.status.busy":"2022-03-08T10:06:40.944527Z","iopub.execute_input":"2022-03-08T10:06:40.944980Z","iopub.status.idle":"2022-03-08T10:06:56.380784Z","shell.execute_reply.started":"2022-03-08T10:06:40.944938Z","shell.execute_reply":"2022-03-08T10:06:56.379996Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from torch.nn import init\n\ndef init_weights(net, init_type='normal', gain=0.02):\n    def init_func(m):\n        classname = m.__class__.__name__\n        if hasattr(m, 'weight') and (classname.find('Conv') != -1 or classname.find('Linear') != -1):\n            if init_type == 'normal':\n                init.normal_(m.weight.data, 0.0, gain)\n            elif init_type == 'xavier':\n                init.xavier_normal_(m.weight.data, gain=gain)\n            elif init_type == 'kaiming':\n                init.kaiming_normal_(m.weight.data, a=0, mode='fan_in')\n            elif init_type == 'orthogonal':\n                init.orthogonal_(m.weight.data, gain=gain)\n            else:\n                raise NotImplementedError('initialization method [%s] is not implemented' % init_type)\n            if hasattr(m, 'bias') and m.bias is not None:\n                init.constant_(m.bias.data, 0.0)\n        elif classname.find('BatchNorm2d') != -1:\n            init.normal_(m.weight.data, 1.0, gain)\n            init.constant_(m.bias.data, 0.0)\n\n    print('initialize network with %s' % init_type)\n    net.apply(init_func)\n\nclass conv_block(nn.Module):\n    def __init__(self,ch_in,ch_out):\n        super(conv_block,self).__init__()\n        self.conv = nn.Sequential(\n            nn.Conv2d(ch_in, ch_out, kernel_size=3,stride=1,padding=1,bias=True),\n            nn.BatchNorm2d(ch_out),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(ch_out, ch_out, kernel_size=3,stride=1,padding=1,bias=True),\n            nn.BatchNorm2d(ch_out),\n            nn.ReLU(inplace=True)\n        )\n\n\n    def forward(self,x):\n        x = self.conv(x)\n        return x\n\nclass up_conv(nn.Module):\n    def __init__(self,ch_in,ch_out):\n        super(up_conv,self).__init__()\n        self.up = nn.Sequential(\n            nn.Upsample(scale_factor=2),\n            nn.Conv2d(ch_in,ch_out,kernel_size=3,stride=1,padding=1,bias=True),\n\t\t    nn.BatchNorm2d(ch_out),\n\t\t\tnn.ReLU(inplace=True)\n        )\n\n    def forward(self,x):\n        x = self.up(x)\n        return x\n    \nclass Attention_block(nn.Module):\n    def __init__(self,F_g,F_l,F_int):\n        super(Attention_block,self).__init__()\n        self.W_g = nn.Sequential(\n            nn.Conv2d(F_g, F_int, kernel_size=1,stride=1,padding=0,bias=True),\n            nn.BatchNorm2d(F_int)\n            )\n        \n        self.W_x = nn.Sequential(\n            nn.Conv2d(F_l, F_int, kernel_size=1,stride=1,padding=0,bias=True),\n            nn.BatchNorm2d(F_int)\n        )\n\n        self.psi = nn.Sequential(\n            nn.Conv2d(F_int, 1, kernel_size=1,stride=1,padding=0,bias=True),\n            nn.BatchNorm2d(1),\n            nn.Sigmoid()\n        )\n        \n        self.relu = nn.ReLU(inplace=True)\n        \n    def forward(self,g,x):\n        g1 = self.W_g(g)\n        x1 = self.W_x(x)\n        psi = self.relu(g1+x1)\n        psi = self.psi(psi)\n\n        return x*psi\n    \nclass AttU_Net(nn.Module):\n    def __init__(self,img_ch=3,output_ch=1):\n        super(AttU_Net,self).__init__()\n        \n        self.Maxpool = nn.MaxPool2d(kernel_size=2,stride=2)\n\n        self.Conv1 = conv_block(ch_in=img_ch,ch_out=64)\n        self.Conv2 = conv_block(ch_in=64,ch_out=128)\n        self.Conv3 = conv_block(ch_in=128,ch_out=256)\n        self.Conv4 = conv_block(ch_in=256,ch_out=512)\n        self.Conv5 = conv_block(ch_in=512,ch_out=1024)\n\n        self.Up5 = up_conv(ch_in=1024,ch_out=512)\n        self.Att5 = Attention_block(F_g=512,F_l=512,F_int=256)\n        self.Up_conv5 = conv_block(ch_in=1024, ch_out=512)\n\n        self.Up4 = up_conv(ch_in=512,ch_out=256)\n        self.Att4 = Attention_block(F_g=256,F_l=256,F_int=128)\n        self.Up_conv4 = conv_block(ch_in=512, ch_out=256)\n        \n        self.Up3 = up_conv(ch_in=256,ch_out=128)\n        self.Att3 = Attention_block(F_g=128,F_l=128,F_int=64)\n        self.Up_conv3 = conv_block(ch_in=256, ch_out=128)\n        \n        self.Up2 = up_conv(ch_in=128,ch_out=64)\n        self.Att2 = Attention_block(F_g=64,F_l=64,F_int=32)\n        self.Up_conv2 = conv_block(ch_in=128, ch_out=64)\n\n        self.Conv_1x1 = nn.Conv2d(64,output_ch,kernel_size=1,stride=1,padding=0)\n\n\n    def forward(self,x):\n        # encoding path\n        x1 = self.Conv1(x)\n\n        x2 = self.Maxpool(x1)\n        x2 = self.Conv2(x2)\n        \n        x3 = self.Maxpool(x2)\n        x3 = self.Conv3(x3)\n\n        x4 = self.Maxpool(x3)\n        x4 = self.Conv4(x4)\n\n        x5 = self.Maxpool(x4)\n        x5 = self.Conv5(x5)\n\n        # decoding + concat path\n        d5 = self.Up5(x5)\n        x4 = self.Att5(g=d5,x=x4)\n        d5 = torch.cat((x4,d5),dim=1)        \n        d5 = self.Up_conv5(d5)\n        \n        d4 = self.Up4(d5)\n        x3 = self.Att4(g=d4,x=x3)\n        d4 = torch.cat((x3,d4),dim=1)\n        d4 = self.Up_conv4(d4)\n\n        d3 = self.Up3(d4)\n        x2 = self.Att3(g=d3,x=x2)\n        d3 = torch.cat((x2,d3),dim=1)\n        d3 = self.Up_conv3(d3)\n\n        d2 = self.Up2(d3)\n        x1 = self.Att2(g=d2,x=x1)\n        d2 = torch.cat((x1,d2),dim=1)\n        d2 = self.Up_conv2(d2)\n\n        d1 = self.Conv_1x1(d2)\n\n        return nn.Sigmoid()(d1)\n    \nmodel = AttU_Net(img_ch=3,output_ch=1).to(device)\ninit_weights(model)","metadata":{"execution":{"iopub.status.busy":"2022-03-08T10:06:56.382282Z","iopub.execute_input":"2022-03-08T10:06:56.383001Z","iopub.status.idle":"2022-03-08T10:06:59.561632Z","shell.execute_reply.started":"2022-03-08T10:06:56.382962Z","shell.execute_reply":"2022-03-08T10:06:59.560889Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def dice_coef_metric(pred, label):\n    smooth = 1.0\n    intersection = (pred*label).sum()\n    union = pred.sum() + label.sum()\n    return (2*intersection + smooth)/(union + smooth)\n\ndef dice_coef_loss(pred, label):\n    smooth = 1.0\n    intersection = 2.0 * (pred * label).sum() + smooth\n    union = pred.sum() + label.sum() + smooth\n    return 1 - (intersection / union)\n\ndef bce_dice_loss(pred, label):\n    dice_loss = dice_coef_loss(pred, label)\n    bce_loss = nn.BCELoss()(pred, label)\n    return dice_loss + bce_loss\n\ndef compute_iou(model, loader, threshold=0.3):\n    valloss = 0\n    with torch.no_grad():\n        for step, (data, target) in enumerate(loader):\n            data = data.to(device)\n            target = target.to(device)\n\n            outputs = model(data)\n            out_cut = np.copy(outputs.data.cpu().numpy())\n            out_cut[np.nonzero(out_cut < threshold)] = 0.0\n            out_cut[np.nonzero(out_cut >= threshold)] = 1.0\n\n            loss = dice_coef_metric(out_cut, target.data.cpu().numpy())\n            valloss += loss\n\n    return valloss / step\n\ndef iou(y_true, y_pred):\n    intersection = torch.sum(y_true * y_pred)\n    return (intersection + 1.) / (torch.sum(y_true) + torch.sum(y_pred) - intersection + 1.)\n\ndef falsepos(y_true, y_pred):\n    intersection = torch.sum(y_true * y_pred)\n    return torch.sum(y_pred) - intersection\n\ndef falseneg(y_true, y_pred):\n    intersection = torch.sum(y_true * y_pred)\n    return torch.sum(y_true) - intersection\n\ndef precision(y_true, y_pred):\n    intersection = torch.sum(y_true * y_pred)\n    return intersection / (torch.sum(y_pred) + 1.)\n\ndef recall(y_true, y_pred):\n    intersection = torch.sum(y_true * y_pred)\n    return intersection / (torch.sum(y_true) + 1.)\n\ndef fscore(y_true, y_pred):\n    presci = precision(y_true, y_pred)\n    rec = recall(y_true, y_pred)\n    return 2*(presci * rec)/(presci + rec)\n\ndef weighted_fscore_loss(prew=1, recw=1):\n    def fscore_loss(y_true, y_pred):\n        presci = precision(y_true, y_pred)\n        rec = recall(y_true, y_pred)\n        return -(prew+recw)*(presci * rec)/(prew*presci + recw*rec)\n    return fscore_loss","metadata":{"execution":{"iopub.status.busy":"2022-03-08T10:06:59.562759Z","iopub.execute_input":"2022-03-08T10:06:59.563188Z","iopub.status.idle":"2022-03-08T10:06:59.580275Z","shell.execute_reply.started":"2022-03-08T10:06:59.563149Z","shell.execute_reply":"2022-03-08T10:06:59.579564Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\nscheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'max', patience=3, factor=0.5)\nmeasures = {'dice_coef':dice_coef_metric,\n           'iou':iou,\n           'precision':precision,\n           'recall':recall,\n           'fscore':fscore}","metadata":{"execution":{"iopub.status.busy":"2022-03-08T10:06:59.581693Z","iopub.execute_input":"2022-03-08T10:06:59.582178Z","iopub.status.idle":"2022-03-08T10:06:59.593546Z","shell.execute_reply.started":"2022-03-08T10:06:59.582140Z","shell.execute_reply":"2022-03-08T10:06:59.592865Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train_model(model_name, model, dataloader, loss_func, optimizer, scheduler, measures, num_epochs, save_path='attn_unet.pt'):\n    print('-'*10 , model_name, '-'*10)\n    \n    train_log = {k:[] for k in measures.keys()}\n    train_log['loss'] = []\n    val_log = {k:[] for k in measures.keys()}\n    val_log['loss'] = []\n    \n    best_val_score = 0.\n    best_wts = copy.deepcopy(model.state_dict())\n    \n    for epoch in range(num_epochs):\n        \n        print(f'Epoch {epoch+1}/{num_epochs}')\n        \n        for phase in ['train', 'val']:\n            if phase == 'train':\n                model.train()\n            else:\n                model.eval()\n                \n            running_losses = []\n            measurements = {k:0. for k in measures.keys()}\n\n            for i, (images, masks) in enumerate(tqdm(dataloader[phase])):\n                images = images.to(device)\n                masks = masks.to(device)\n                \n                optimizer.zero_grad()\n\n                outputs = model(images)\n                loss = loss_func(outputs, masks)\n                running_losses.append(loss.item())\n        \n                for (k,mobj) in measures.items():\n                    measurements[k] += mobj(outputs, masks).item()\n                \n                if phase=='train':\n                    loss.backward()\n                    optimizer.step()\n                           \n            for k in measures.keys():\n                measurements[k] = measurements[k] / len(dataloader[phase])\n            measurements['loss'] = np.array(running_losses).mean()\n            \n            if phase=='val':\n                scheduler.step(measurements['dice_coef'])\n                \n            if phase=='train':\n                for k in measurements.keys():\n                    train_log[k].append(measurements[k])\n            else:\n                for k in measurements.keys():\n                    val_log[k].append(measurements[k])\n                \n            print(f'{phase}:', end='\\t')\n            for k,v in measurements.items():\n                print(\" {}:{:.4f}\".format(k,v), end='  ')\n            print()\n            print(f'current lr:', optimizer.param_groups[0]['lr'])\n            \n            if phase=='val' and measurements['dice_coef'] > best_val_score:\n                print(f\"New score: {measurements['dice_coef']:.4f}\\t Previous score: {best_val_score:.4f}\")\n                best_val_score = measurements['dice_coef']\n                best_wts = copy.deepcopy(model.state_dict())\n                torch.save(model.state_dict(), save_path)\n                \n    model.load_state_dict(best_wts)\n    print(f'Training Completed. Best score: {best_val_score}')\n    return train_log, val_log","metadata":{"execution":{"iopub.status.busy":"2022-03-08T10:06:59.596844Z","iopub.execute_input":"2022-03-08T10:06:59.597084Z","iopub.status.idle":"2022-03-08T10:06:59.614200Z","shell.execute_reply.started":"2022-03-08T10:06:59.597056Z","shell.execute_reply":"2022-03-08T10:06:59.613103Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"num_epochs = 5\ntrain_log, val_log = train_model(\"AttnUNet\", model, dataloader, bce_dice_loss, optimizer, scheduler, measures, num_epochs)","metadata":{"execution":{"iopub.status.busy":"2022-03-08T10:06:59.615449Z","iopub.execute_input":"2022-03-08T10:06:59.615841Z","iopub.status.idle":"2022-03-08T10:11:15.103005Z","shell.execute_reply.started":"2022-03-08T10:06:59.615804Z","shell.execute_reply":"2022-03-08T10:11:15.102136Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_model_history(model_name, train_log, val_log, num_epochs):\n    n = len(train_log)\n    x = np.arange(num_epochs)\n    fig = plt.figure(figsize=(20, 10))\n    plt.title(f\"{model_name}\", fontsize=15)\n    for i, k in enumerate(train_log.keys()):       \n        plt.subplot(n//2, 2, i+1)\n        plt.plot(x, train_log[k], label=f'train_{k}', lw=3, c=\"b\")\n        plt.plot(x, val_log[k], label=f'val_{k}', lw=3, c=\"r\")\n        plt.legend(fontsize=12)\n        plt.xlabel(\"Epoch\", fontsize=15)\n        plt.ylabel(f\"{k}\", fontsize=15)\n    plt.show()\nplot_model_history('Attn_UNet', train_log, val_log, num_epochs)","metadata":{"execution":{"iopub.status.busy":"2022-03-08T10:15:45.127307Z","iopub.execute_input":"2022-03-08T10:15:45.127898Z","iopub.status.idle":"2022-03-08T10:15:46.225499Z","shell.execute_reply.started":"2022-03-08T10:15:45.127852Z","shell.execute_reply":"2022-03-08T10:15:46.223902Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Evaluation test set\ntest_log = {k:0. for k in measures.keys()}\nwith torch.no_grad():\n    for i, (images, masks) in enumerate(tqdm(dataloader['test'])):\n        images = images.to(device)\n        masks = masks.to(device)\n        outputs = model(images)\n        for (k,mobj) in measures.items():\n            test_log[k] += mobj(outputs, masks).item()\n    for k in measures.keys():\n        test_log[k] = test_log[k] / len(dataloader['test'])\n        \nprint(test_log)","metadata":{"execution":{"iopub.status.busy":"2022-03-08T10:12:35.963496Z","iopub.execute_input":"2022-03-08T10:12:35.963919Z","iopub.status.idle":"2022-03-08T10:13:42.188643Z","shell.execute_reply.started":"2022-03-08T10:12:35.963877Z","shell.execute_reply":"2022-03-08T10:13:42.187827Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_sample = val_df.sample(1).values[0]\nimage = cv2.resize(cv2.imread(test_sample[0]), (IMG_SIZE, IMG_SIZE))\nmask = cv2.resize(cv2.imread(test_sample[1]), (IMG_SIZE, IMG_SIZE))\n\n# pred\npred = torch.tensor(image.astype(np.float32) / 255.).unsqueeze(0).permute(0,3,1,2)\npred = T.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))(pred)\npred = model(pred.to(device))\npred = pred.detach().cpu().numpy()[0, 0,:,:]\n\npred_t = np.copy(pred)\npred_t[np.nonzero(pred_t < 0.3)] = 255\npred_t[np.nonzero(pred_t >= 0.3)] = 0\npred_t = pred_t.astype(\"uint8\")\n# pred_t = np.dstack([pred_t, pred_t, pred_t])\n# plot\nfig, ax = plt.subplots(nrows=2,  ncols=2, figsize=(10, 10))\n\nax[0, 0].imshow(image)\nax[0, 0].set_title(\"image\")\nax[0, 1].imshow(mask)\nax[0, 1].set_title(\"mask\")\nax[1, 0].imshow(pred)\nax[1, 0].set_title(\"prediction\")\nax[1, 1].imshow(pred_t)\nax[1, 1].set_title(\"prediction with threshold\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-03-08T10:26:27.780940Z","iopub.execute_input":"2022-03-08T10:26:27.781223Z","iopub.status.idle":"2022-03-08T10:26:28.358783Z","shell.execute_reply.started":"2022-03-08T10:26:27.781190Z","shell.execute_reply":"2022-03-08T10:26:28.358133Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def makeAnnotatedImage(x, y, label):\n    \"\"\"\n    x: images\n    y: prediction\n    label: mask\n    \"\"\"\n    y = y.cpu().detach().numpy()[0,:,:]\n    label = label.cpu().detach().numpy()[0,:,:]\n    \n    imgs = []\n    orig = x.cpu().detach().numpy()\n    orig = (orig + 1)*127\n    orig = orig.astype(np.uint8)\n    orig = np.dstack((orig[0,:,:], orig[1,:,:], orig[2,:,:]))\n    \n    img = cv2.cvtColor(orig, cv2.COLOR_BGR2RGB)\n    cv2.putText(img, 'Original', (5,20), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0,0,0,0), 2)\n    imgs.append(img)\n\n    orig = cv2.cvtColor(orig, cv2.COLOR_RGB2HSV)\n\n    # apply prediction and label markings\n    img = np.copy(orig)\n    h = img[:,:,0]\n    s = img[:,:,1]\n    h[label > 0.75] = 100 # BLUE\n    s[label > 0.75] = 250\n    cv2.putText(img, 'Label', (5,20), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0,0,0,0), 2)\n    imgs.append(cv2.cvtColor(img, cv2.COLOR_HSV2BGR))\n\n    img = np.copy(orig)\n    h = img[:,:,0]\n    s = img[:,:,1]\n    h[np.nonzero(y > 0.75)] = 50 # GREEN\n    s[np.nonzero(y > 0.75)] = 250\n    cv2.putText(img, 'Prediction', (5,20), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0,0,0,0), 2)\n    imgs.append(cv2.cvtColor(img, cv2.COLOR_HSV2BGR))\n\n    img = np.copy(orig)\n    h = img[:,:,0]\n    s = img[:,:,1]\n    h[y > .75] += 50 # GREEN\n    s[y > .75] = 250\n    h[label > .75] += 100 # BLUE\n    s[label > .75] = 250\n    cv2.putText(img, 'Combined', (5,20), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0,0,0,0), 2)\n    imgs.append(cv2.cvtColor(img, cv2.COLOR_HSV2BGR))\n\n    final = np.hstack(imgs)\n    return final","metadata":{"execution":{"iopub.status.busy":"2022-03-08T10:42:28.706741Z","iopub.execute_input":"2022-03-08T10:42:28.707006Z","iopub.status.idle":"2022-03-08T10:42:28.723216Z","shell.execute_reply.started":"2022-03-08T10:42:28.706976Z","shell.execute_reply":"2022-03-08T10:42:28.720323Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"images, masks = next(iter(dataloader['test']))\noutputs = model(images.to(device))\nsamples = []\n\nfor idx in range(len(images)):\n    x, y, output = images[idx], masks[idx], outputs[idx]\n    samples.append(makeAnnotatedImage(x, output, y))\n    \nfor idx in range(len(samples)):\n    plt.figure()\n    plt.axis('off')\n    plt.imshow(samples[idx])","metadata":{"execution":{"iopub.status.busy":"2022-03-08T10:45:59.983275Z","iopub.execute_input":"2022-03-08T10:45:59.983988Z","iopub.status.idle":"2022-03-08T10:46:02.521621Z","shell.execute_reply.started":"2022-03-08T10:45:59.983944Z","shell.execute_reply":"2022-03-08T10:46:02.520980Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_samples = test_df.sample(len(test_df)).values\n\ndef batch_preds_overlap(model, samples):\n    \"\"\"\n    Computes prediction on the dataset\n    \n    Returns: list with images overlapping with predictions\n    \n    \"\"\"\n    prediction_overlap = []\n    for test_sample in samples:\n\n         # sample\n            \n        image = cv2.resize(cv2.imread(test_sample[0]),(IMG_SIZE, IMG_SIZE))\n        image =  image / 255.\n        ground_truth = cv2.resize(cv2.imread(test_sample[1], 0), (IMG_SIZE, IMG_SIZE)).astype(\"uint8\")\n\n        # pred\n        prediction = torch.tensor(image).unsqueeze(0).permute(0,3,1,2)\n        prediction = T.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))(prediction)\n        prediction = model(prediction.to(device).float())\n        prediction = prediction.detach().cpu().numpy()[0,0,:,:]\n\n        prediction[np.nonzero(prediction < 0.3)] = 0.0\n        prediction[np.nonzero(prediction >= 0.3)] = 255.\n        prediction = prediction.astype(\"uint8\")\n\n        # overlap \n        original_img = cv2.resize(cv2.imread(test_sample[0]),(IMG_SIZE, IMG_SIZE))\n\n        _, thresh_gt = cv2.threshold(ground_truth, 127, 255, 0)\n        _, thresh_p = cv2.threshold(prediction, 127, 255, 0)\n        contours_gt, _ = cv2.findContours(thresh_gt, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n        contours_p, _ = cv2.findContours(thresh_p, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n\n        overlap_img = cv2.drawContours(original_img, contours_gt, 0, (0, 255, 0), 1)\n        overlap_img = cv2.drawContours(overlap_img, contours_p, 0, (255,36,0), 1)#255,0,0\n        prediction_overlap.append(overlap_img)\n\n    return prediction_overlap\n    \nprediction_overlap_r = batch_preds_overlap(model, test_samples)","metadata":{"execution":{"iopub.status.busy":"2022-03-08T10:42:45.542809Z","iopub.execute_input":"2022-03-08T10:42:45.543067Z","iopub.status.idle":"2022-03-08T10:45:00.515658Z","shell.execute_reply.started":"2022-03-08T10:42:45.543035Z","shell.execute_reply":"2022-03-08T10:45:00.514896Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pred_overlap_5x1_r = []\npred_overlap_5x3_r = []\n\nfor i in range(5, 105+5, 5):\n    pred_overlap_5x1_r.append(np.hstack(np.array(prediction_overlap_r[i-5:i])))\n\nfor i in range(3, 21+3, 3):\n    pred_overlap_5x3_r.append(np.vstack(pred_overlap_5x1_r[i-3:i]))","metadata":{"execution":{"iopub.status.busy":"2022-03-08T10:45:00.517260Z","iopub.execute_input":"2022-03-08T10:45:00.517488Z","iopub.status.idle":"2022-03-08T10:45:00.533610Z","shell.execute_reply.started":"2022-03-08T10:45:00.517454Z","shell.execute_reply":"2022-03-08T10:45:00.532859Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_plate_overlap(batch_preds, title, num):\n    plt.figure(figsize=(15, 15))\n    plt.imshow(batch_preds)\n    plt.axis(\"off\")\n\n    plt.figtext(0.76,0.75,\"Green - Ground Truth\", va=\"center\", ha=\"center\", size=20,color=\"lime\");\n    plt.figtext(0.26,0.75,\"Red - Prediction\", va=\"center\", ha=\"center\", size=20, color=\"#ff0d00\");\n    plt.suptitle(title, y=.80, fontsize=20, weight=\"bold\", color=\"#00FFDE\");\n\n    fn = \"_\".join((title+str(num)).lower().split()) + \".png\"\n    plt.savefig(fn, bbox_inches='tight', pad_inches=0.2, transparent=False, facecolor='black')\n    plt.close()\n\ntitle = \"Predictions of Attn_UNet\"\n\nfor num, batch in enumerate(pred_overlap_5x3_r):\n    plot_plate_overlap(batch,title, num)","metadata":{"execution":{"iopub.status.busy":"2022-03-08T10:45:00.535179Z","iopub.execute_input":"2022-03-08T10:45:00.535452Z","iopub.status.idle":"2022-03-08T10:45:04.919901Z","shell.execute_reply.started":"2022-03-08T10:45:00.535413Z","shell.execute_reply":"2022-03-08T10:45:04.919171Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from PIL import Image\n\ndef make_gif(title):\n    base_name = \"_\".join(title.lower().split())\n\n    base_len = len(base_name) \n    end_len = len(\".png\")\n    fp_in = f\"{base_name}*.png\"\n    fp_out = f\"{base_name}.gif\"\n\n    img, *imgs = [Image.open(f) \n                  for f in sorted(glob.glob(fp_in), key=lambda x : int(x[base_len:-end_len]))]\n\n    img.save(fp=fp_out, format='GIF', append_images=imgs,\n             save_all=True, duration=2000, loop=0)\n    \n    return fp_out\n\nfn = make_gif(title)","metadata":{"execution":{"iopub.status.busy":"2022-03-08T10:45:04.922029Z","iopub.execute_input":"2022-03-08T10:45:04.922287Z","iopub.status.idle":"2022-03-08T10:45:05.352272Z","shell.execute_reply.started":"2022-03-08T10:45:04.922259Z","shell.execute_reply":"2022-03-08T10:45:05.351507Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from IPython.display import Image as Image_display\nwith open(fn,'rb') as f:\n    display(Image_display(data=f.read(), format='png'))","metadata":{"execution":{"iopub.status.busy":"2022-03-08T10:45:05.353561Z","iopub.execute_input":"2022-03-08T10:45:05.353932Z","iopub.status.idle":"2022-03-08T10:45:05.400781Z","shell.execute_reply.started":"2022-03-08T10:45:05.353896Z","shell.execute_reply":"2022-03-08T10:45:05.400162Z"},"trusted":true},"execution_count":null,"outputs":[]}]}